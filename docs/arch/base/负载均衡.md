# 负载均衡

## HAProxy

## Nginx

### 模块

#### 1. main模块

全局设置填写的是Nginx的全局配置，在此区域填写的内容会被应用到Nginx全局，例如修改Nginx默认的用户名（默认为nobody）可以在配置文件开头加上 `user nginx` 这样Nginx运行的用户就变成了 `nginx` 。常用的全局配置项还有：

* `worker_processes` Nginx开启的子进程数。
* `error_log` 定义全局错误日志文件，可选值有：debug、info、notice、warn、error、crit。
* `pid` 指定进程id的存储文件位置。
* `worker_rlimit_nofile` 指定Nginx进程最多可以打开的文件描述符数目。

一份示例如下：

```
# 定义Nginx运行的用户和用户组
user www www;

# Nginx进程数（建议为CPU总核心数，或者设置为auto）。
worker_processes 8;

# 定义全局错误日志类型
error_log /var/log/nginx/error.log info;

# 进程文件
pid /var/run/nginx.pid;

# 一个Nginx进程打开最多可以打开的文件描述符数目（建议与 ulimit -n 的值保持一致）。
worker_rlimit_nofile 65535;
```

一般而言此处的全局配置都可以保留默认设置（即什么都不用写）。

#### 2. events模块

events模块来用指定Nginx的工作模式和工作模式及连接数上限，示例如下：

```
events {
  # 参考事件模型，可选值有：kqueue、rtsig、epoll、/dev/poll、select、poll。
  # epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型。
  # FreeBSD或者macOS则使用kqueue模型。
  use epoll;
  # 单个进程最大连接数（默认是1024，最大连接数=连接数*进程数）
  worker_connections 65535;
}
```

进程的最大连接数受Linux系统进程的最大打开文件数限制，只有在执行操作系统命令 `ulimit -n 65536` 后worker_connections的设置才能生效。

#### 3. http模块

http部分是配置文件最核心的部分，它包括了绝大部分HTTP服务器相关属性的配置，例如是否使用Keepalive，是否使用gzip进行压缩等，它的里面还包括了server和upstream这些子模块，这些模块都是Nginx负载均衡的重要配置部分。

```
# 配置http服务器
http {
	# 文件扩展名与文件类型映射表
    include mime.types;
    # 默认文件类型
    default_type application/octet-stream;
    # 默认编码
    charset utf-8;
    # 服务器名字的hash表大小
    server_names_hash_bucket_size 128;
    # 缓冲区代理缓冲用户端请求的最大字节数
    client_body_buffer_size 128k;
    # 允许客户端请求的最大单文件字节数。
    client_max_body_size 10m;
    # 开启高效文件传输模式，启用之后Nginx会调用sendfile函数来输出文件。
    # IO负载较大的应用，建议设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。
    sendfile on;
    # 开启目录列表访问（默认关闭）。
    autoindex on;
    # 防止网络阻塞
    tcp_nopush on;
    tcp_nodelay on;
    # 长连接超时时间，单位是秒
    keepalive_timeout 120;

    # gzip模块设置
    gzip on; # 开启gzip压缩输出
    gzip_min_length 1k; # 最小压缩文件大小
    gzip_buffers 4 16k; # 压缩缓冲区
    gzip_http_version 1.1; # 压缩版本
    gzip_comp_level 2; # 压缩等级
    # 压缩类型，默认就已经包含text/html，所以下面就不用再写了。
    gzip_types text/plain application/x-javascript text/css application/xml;
    # 会在响应头加个Vary: Accept-Encoding，可以让前端的缓存服务器缓存经过gzip压缩的页面。
    gzip_vary on;
    # 开启限制IP连接数的时候需要使用
    limit_zone crawler $binary_remote_addr 10m;

    upstream project_name {
        .....
    }
    server {
        ....
    }
}
```

http模块的设置项非常庞杂，此处列举的只是很小的一部分，本节内容主要为Nginx负载均衡，就不在此处赘述。感兴趣的读者可以在Nginx官方文档中查找相关资料：https://www.nginx.com/resources/wiki/ 。

#### 4. server模块

sever模块是http的子模块，它可以定义一个虚拟主机，基本配置示例如下：

```
server {
    listen 2333;
    server_name localhost 1.2.3.4 www.example.com;
    root /nginx/www/path/;
    index index.php index.html index.htm; 
    charset utf-8;
    access_log usr/local/var/log/host.access.log main;
    aerror_log usr/local/var/log/host.error.log error;
    ....
}
```

* `server{ }` 表示虚拟主机配置范围。 
* `listen` 用于指定虚拟主机的服务端口。 
* `server_name` 用来指定IP地址或者域名，多个域名之间用空格分开。 
* `root` 表示在 `server` 这个虚拟主机内Web服务的根目录。
* `index` 定义默认首页地址。
* `charset` 设置网页的默认编码格式。
* `access_log` 指定虚拟主机的访问日志存放路径，后面接上日志的输出格式。

server模块的配置也有很多，其中location模块也是server模块的子模块。

#### 5. location模块

location模块是Nginx中可自定义程度最高的模块，location就如同它的名字一样是用来定位解析URL的，通过正则匹配，用户可以通过location指令实现对网页的各种处理。

例如下面反代理的示例：

```
location / {
    root   /nginx/www/path;
    index  index.php index.html index.htm;
}
```

上面示例中 `location /` 表示匹配访问根目录。相关资料：

[nginx location](http://seanlook.com/2015/05/17/nginx-location-rewrite/)

#### 6. upstram模块

upstram模块又称负载均衡模块，下面先通过一个简单的调度算法来简单认识这个模块：

```
upstream example.com {
    fair;
    server 172.17.1.1:80;
    server 172.17.1.2:8080 down;
    server 172.17.1.3:9999 max_fails=3 fail_timeout=20s max_conns=1000;
    server 172.17.1.4:2333 backup;
}
```

在上面的例子中，通过 `upstream` 指令定义了一个负载均衡器的名称为 `example.com` ，此处的名称可以任意指定，不一定是一个域名。

其中的 `fair` 是一种负载均衡调度算法，后面会介绍。然后 `server` 表示真实服务器群组，后面接真实服务器IP。

down表示该server不参与负载均衡。backup表示预留的备份机器，只有当其他所有的非backup机器出现故障或者异常忙碌的时候，才会请求backup机器，所以这台机器的负载压力最轻。

max_fails表示允许请求失败的次数（默认为1次），当超过最大次数时返回proxy_next_upstream模块定义的错误。fail_timeout表示在经理max_fails次失败后，暂停服务的时间。max_conns表示限制分配给后端服务器处理的最大连接数量，超过这个数量，将不会分配新的连接给它。

upstram模块中还有一个resolve选项需要配合http模块使用，例如：

```
http {
    resolver 10.0.0.1;
    upstream u {
        ...
        server example.com resolve;
    }
```

在http模块下配置resolver指令，指定域名解析服务为example.com域名，并且由10.0.0.1服务器来负责解析。

以上就是upstram模块的常见配置说明，更多内容可以参考官方文档：

http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server

### 负载均衡算法

目前Nginx负载均衡模块共有4种调度算法，分别是:

1. weight轮询（Nginx默认调度算法）。每个请求按照请求的时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，Nginx轮询列表将自动去除该后端服务器，使用户访问不受影响。weight用于指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下，服务器性能强大的权重设置高一些可以分到更多的任务，减轻性能较弱机器的运行压力。

2. ip_hash。根据hash算法把每个请求中的访问IP作处理，使得来自同一个IP的访客固定访问一个后端服务器，这种方式可以简单而有效地解决动态网页存在的会话（session）共享问题。

3. fair。这个负载均衡算法相较于前面两种更加智能。这个算法可以根据页面大小和加载时间长短智能地进行负载均衡，简单来说就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。不过Nginx默认是不支持fair的，用户需要手动下载编译安装Nginx的upstream_fair模块。

4. url_hash。根据hash算法把每个请求中的访问url作处理，使得来自同一个url的请求固定定向到同一个后端服务器，这样可以提高后端缓存服务器的效率。Nginx在1.7.2版本集成了url_hash模块，旧版本用户需要手动编译安装Nginx的hash模块。

下面来看各个调度算法的具体配置案例。

#### 1. 权重轮询

先来一个最简单的，weight轮询调度：

```
upstream upstream.example.com {
    server 172.17.1.1:80;
    server 172.17.1.2:8080;
    server 172.17.1.3:9999 max_fails=3 fail_timeout=20s max_conns=1000;
    server 172.17.1.4:2333 backup;
}
server {
    listen 80;
    server_name example.com;
    access_log /usr/local/var/log/nginx/example.com.access.log main;
    error_log /usr/local/var/log/nginx/example.com.error.log error;
    location / {
        proxy_pass http://upstream.example.com;
        proxy_set_header  X-Real-IP  $remote_addr;
    }
}
```

然后重启Nginx：`nginx -s reload`，打开浏览器输入`example.com`，刷新几次，如果每个后端服务的显示界面不同，那么在这几次刷新中看到的页面应该是逐一变换的（逐一显示1、2、3三台服务器的界面，4号服务器在这里是备份，所以不显示），这说明我们的负载均衡起作用了。

现在其中一台后端服务器的服务停掉，演示中停掉的是172.17.1.3这台后端服务器。然后重启 前端负载的服务器中的Nginx，再刷新`example.com`，就能看到逐一变化显示的只有1、2两台服务器了（因为3号服务器停止，4号备份服务器还处于备份状态）。

接下来，我们将1、2号服务器的服务停掉，然后刷新网页，此时因为1到3号服务器都停止服务了，所以4号备份服务器就开始工作了，此时网页刷新只会出现4号服务器的页面。

#### 2. IP哈希

这种调度算法配置起来也不复杂：

```
upstream example.com {
    ip_hash;
    server 172.17.1.1:80 weight=1;
    server 172.17.1.2:8080 weight=1;
    server 172.17.1.3:9999 weight=1 max_fails=3 fail_timeout=20s;
    server 172.17.1.4:2333 weight=1 backup;
}
```

重启Nginx，不断刷新，页面始终都是1号服务器的页面。

现在将2号服务器的权重增大：

```
upstream example.com {
    ip_hash;
    server 172.17.1.1:80 weight=1;
    server 172.17.1.2:8080 weight=10;
    server 172.17.1.3:9999 weight=1 max_fails=3 fail_timeout=20s;
    server 172.17.1.4:2333 weight=1;
}
```

重启Nginx之后，网页固定显示2号服务器。此时如果关掉2号服务器的服务，再刷新网页，又会出现1号服务器的页面，因为权重高的2号已经不在运行状态了。

其实，在ip_hash模式下，最好不要设置`weight`参数，因为这将会导致流量分配不均匀。同时，在ip_hash模式下，`backup`参数不可用，会报错。因为，访问已经固定，备份已经不存在意义了。

因此当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能有weight和backup。

#### 3. Fair调度

这种调度算法根据服务器的响应时间来分配请求，响应时间短的优先分配。由于fair模块是第三方提供的，所以需要用户手动编译安装，将fair模块添加到Nginx中。

假设Nginx安装在/usr/nginx目录下，而且安装时没有添加fair模块，那么可以在Github上下载fair模块的源码。下载地址：https://github.com/gnosek/nginx-upstream-fair

```
root@ops-admin:~# cd /usr
root@ops-admin:~# wget https://github.com/gnosek/nginx-upstream-fair/archive/master.zip
root@ops-admin:~# unzip master.zip
```

解压后的目录名为：nginx-upstream-fair-master

重新编译Nginx，将fair模块添加到编译参数，假设Nginx源码目录在`/usr/nginx-1.11.0`

```
root@ops-admin:~# cd /usr/nginx-nginx-1.11.0
root@ops-admin:~# ./configure --prefix=/usr/nginx --add-module=/usr/nginx-upstream-fair-master
root@ops-admin:~# make
```

> 不要执行`make install`，这样会覆盖之前Nginx的配置。

在objs目录下，找到编译后的Nginx执行程序，将新编译的Nginx可执行程序拷贝到`/usr/nginx/sbin/`目录下，覆盖之前安装的Nginx执行程序。

重启Nginx服务：
```
root@ops-admin:~# killall nginx
root@ops-admin:~# nginx
```

接下来配置使用fair负载模块：

```
upstream example.com {
    fair;
    server 172.17.1.1:80;
    server 172.17.1.2:8080 down;
    server 172.17.1.3:9999 max_fails=3 fail_timeout=20s max_conns=1000;
    server 172.17.1.4:2333 backup;
}
```

> 由于采用fair负载策略，配置weigth参数改变负载权重将无效。

#### 4. URL哈希

按请求url的hash结果来分配请求，使每个url定向到同一个后端服务器，有利于服务器缓存效率。

在Nginx的1.7.2版本以后，url_hash模块已经集成到了Nginx源码中，不需要手动下载源码编译。旧版本用户可以在后面给出的下载地址中下载编译，方法与上面fair模块相同。下载地址：https://github.com/evanmiller/nginx_upstream_hash 

下面是一份配置案例：
```
upstream example.com {
    hash $request_uri;
    server 172.17.1.1:80;
    server 172.17.1.2:8080;
    server 172.17.1.3:9999 max_fails=3 fail_timeout=20s max_conns=1000;
    server 172.17.1.4:2333;
}
```

### 会话一致性

用户使用浏览器和服务端交互的时候，通常会在本地保存一些信息，例如登录信息、信息缓存等等，这个过程被称为会话 (Session)，通过使用唯一的Session ID进行标识。例如在网上购物，购物车的使用就是一个会话的应用场景，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制。此外HTTP客户端一般也会缓存一些数据在本地，以便减少请求，提高性能。

在多台后台服务器的环境下，为了确保一个客户只和一台服务器通信，势必要使用长连接。为了解决这个问题，一个办法就是让所有后端服务器共享会话这部分的数据，但是共享服务器的存储就成为了着呢个系统的瓶颈，效率也会变得低下。

还有一个办法是使用Nginx自带的ip_hash调度算法来做，但如果前端是CDN，或者局域网的客户同时访问服务器，导致出现服务器请求分配不均衡，不能保证每次访问都粘滞（Sticky）在同一台服务器。

所以最简单的办法就是会话一致性——把相同的会话请求发送到同一台后端服务器中。在Nginx中的会话一致性是通过sticky模块开启的，会话一致性和之前的负载均衡算法之间并不冲突，只是需要在第一次分配之后，该会话的所有请求都分配到那个相同的后端服务器上面。

![图4-9 sticky模块工作流程图](images/图4-9 sticky模块工作流程图.jpg)

目前支持三种模式的会话一致性：

1. Cookie插入

   在后端服务器第一次响应之后，Nginx会在其响应头部插入一个会话cookie，实际上就是负载均衡器（Nginx）向客户端（用户浏览器）添加cookie，之后客户端接下来的请求都会带有这个cookie值，Nginx根据这个cookie判断请求需要转发给哪个后端服务器。

   ```shell
   upstream backend {
       server backend1.example.com;
       server backend2.example.com;

       sticky cookie srv_id expires=1h domain=.example.com path=/;
   }
   ```

   上面的 srv_id 代表了 cookie 的名字，而后面的参数 expires、domain、path 都是可选的。

2. Sticky Routes

   在后端服务器第一次响应之后，产生一个路由（route）信息，路由信息通常会从cookie/URI信息中提取。

   ```shell
   upstream backend {
       server backend1.example.com route=a;
       server backend2.example.com route=b;

       sticky route $route_cookie $route_uri;
   }
   ```

   这样Nginx会按照顺序搜索`$route_cookie`、`$route_uri`参数并选择第一个非空的参数用作route，而如果所有的参数都是空的，就使用上面默认的负载均衡算法决定请求分发给哪个后端服务器。



3. Learn

   Learn模式中Nginx会自动监测请求和响应中的会话信息，而且通常需要会话一致性的请求、应答中都会带有会话信息，这和第一种方式相比是不用增加cookie，而是动态学习已有的会话。这种方式需要使用到zone结构，在Nginx中zone都是共享内存，可以在多个worker process中共享数据用的。

   ```shell
   upstream backend {
      server backend1.example.com;
      server backend2.example.com;

      sticky learn 
          create=$upstream_cookie_examplecookie
          lookup=$cookie_examplecookie
          zone=client_sessions:1m
          timeout=1h;
   }
   ```


   在上面的例子中，该zone名为client_sessions，大小为1兆字节。

### 会话流出

会话流出又称为Session Draining。有时候某些后端服务器因为各种原因需要下线（维护或者升级），为了不让用户感受到服务中断状态，就需要让新的请求不会发送到这个停止服务的后端服务器中。而之前已经分配到这个后端服务器的会话，后续请求还会继续发送给它，直到这个会话最终完成。当所有会话结束，这台后端服务器就会自动下线，退出负载均衡列表。

让某个后端服务器进入`draining`状态，既可以直接修改配置文件，然后通过向`master process`发送信号重新加载配置，也可以采用Nginx的on-the-fly配置方式。下面是以On-The-Fly配置方式演示：

```shell
# 查看后端服务器的列表
$ curl http://localhost/upstream_conf?upstream=backend
server 192.168.56.101:80; # id=0
server 192.168.56.102:80; # id=1
server 192.168.56.103:80; # id=2
# 把后端服务器状态改为draining
$ curl http://localhost/upstream_conf?upstream=backend\&id=1\&drain=1
server 192.168.56.102:80; # id=1 draining
```

通过上面的方式，先列出各个后端服务器的ID号，然后改变指定ID的后端服务器状态。

### 后端健康检测

后端服务器出错主要有两个参数： `max_fails=1` 和 `fail_timeout=10s` ，意味着只要Nginx向后端服务器发送一个请求失败或者没有收到一个响应，就认为该后端服务器在接下来的10s是不可用的状态。

通过周期性地向后端服务器发送这种特殊的请求，并等待收到后端服务器的特殊响应，可以用于确认后端服务器的健康状态。通过health_check可以配置这一功能：

```shell
match server_ok {
    status 200-399;
    header Content-Type = text/html;
    body !~ "maintenance mode";
}
server {
    location / {
        proxy_pass http://backend;
        health_check interval=10 fails=3 passes=2 match=server_ok;
    }
}
```

除了health_check参数是必须的，其余参数都是可选的。其中match参数可以自定义服务器健康的条件，包括返回状态码、头部信息、返回body等（这些条件是“与”关系）。默认情况下Nginx会相隔`interval`秒向后端服务器群组发送一个特殊请求，如果超时或者返回非2xx/3xx的响应码，则认为对应的后端服务器是不可用的，那么Nginx会停止向其发送请求，直到下次该后端服务器通过检查。

在使用了health_check功能后，建议在后端服务器群组创建一个zone，在共享后端服务器群组配置的同时，所有后端服务器的状态也可以在所有的worker process中共享了，否则每个worker process独立保存自己的状态检查计数和结果。

### DNS/HTTP负载均衡

通常现代的网络服务会将一个域名关联到多个主机，在进行DNS查询的时候，默认情况下DNS服务器会以round-robin形式以不同的顺序返回IP地址列表，再将客户请求分配到不同的主机上去。不过这种方式含有固有的缺陷：DNS不会检查主机和IP地址的联通状态，所以分配给客户端的IP不一定可用。DNS的解析结果会在客户端、多个中间DNS服务器不断的缓存，所以后端服务器的分配会很不理想。

Nginx的后端服务器群组中的主机可以配置成域名的形式：在域名的后面添加resolve参数，Nginx会周期性的解析这个域名，当域名解析的结果发生变化的时候会自动生效而不用重启。

```shell
http {
    resolver 10.0.0.1 valid=300s ipv6=off;
    resolver_timeout 10s;
    server {
        location / {
            proxy_pass http://backend;
        }
    }
   
    upstream backend {
        zone backend 32k;
        least_conn;
        ...
        server backend1.example.com resolve;
        server backend2.example.com resolve;
    }
}
```

如果域名解析的结果含有多个IP地址，这些IP地址都会保存到配置文件中去，并且这些IP都参与到自动负载均衡。

### TCP/UDP负载均衡

TCP、UDP的负载均衡都是针对通用程序的，所以之前HTTP协议支持的match条件 (status、header、body) 是没法使用的。TCP和UDP的程序可以根据特定的程序，采用send、expect的方式来进行动态健康检测。

```shell
stream {
    upstream   stream_backend {
        zone   upstream_backend 64k;
        server backend1.example.com:12345;
    }
    match http {
        send      "GET / HTTP/1.0\r\nHost: localhost\r\n\r\n";
        expect ~* "200 OK";
    }
    server {
    listen       12345;
    health_check match=http;
    proxy_pass   stream_backend;
    }
}
```

这种负载适用于LDAP/MySQL/RTMP和DNS/syslog/RADIUS等各种应用场景。

## Apache


## 问题

**1. LVS的工作模式和调度算法？**

**2. 用shell统计ip访问情况，要求分析nginx访问日志，找出访问页面数量在前10位的IP数。**

```shell
awk '{print $1}' access.log | sort | uniq -c | head -n 10
```

**3. MySQL主从复制的关键配置项。**

**4. nginx 限制网速下载**

```conf
limit_conn one 1;  # 限制线程
limit_rate 100k;   # 限制速度

# 前10m不限速，大于10m以128kb/s限速
location /download { 
        limit_rate_after 10m; 
        limit_rate 128k;
}

# 限制IP
allow xxx.xxx.xxx.xxx;
deny all;
```

**[http basic auth](http://wiki.zheng-ji.info/Nginx/http-auth-basic.html)**

**[限制连接数量](http://www.cnblogs.com/wjoyxt/p/6128183.html)**

**[Supervisor](http://wiki.zheng-ji.info/Sys/supervisor.html)**
